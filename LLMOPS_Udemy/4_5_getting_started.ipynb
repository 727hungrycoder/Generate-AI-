{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nJrmtKKzXKx-"
      },
      "source": [
        "## **1. Setting Up MLflow**"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install Dependencies"
      ],
      "metadata": {
        "id": "QGm5rp4JXs5r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mlflow==2.7.1 numpy==1.26.2 plotly==5.15.0 pandas==1.3.5 transformers==4.43.3"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vEH19Qt7XamW",
        "outputId": "cda63a24-fd4f-4e1f-f301-848dc19ffe9e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting mlflow==2.7.1\n",
            "  Downloading mlflow-2.7.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting numpy==1.26.2\n",
            "  Downloading numpy-1.26.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.2/61.2 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: plotly==5.15.0 in /usr/local/lib/python3.10/dist-packages (5.15.0)\n",
            "Collecting pandas==1.3.5\n",
            "  Downloading pandas-1.3.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting transformers==4.43.3\n",
            "  Downloading transformers-4.43.3-py3-none-any.whl.metadata (43 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.7/43.7 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from mlflow==2.7.1) (8.1.7)\n",
            "Requirement already satisfied: cloudpickle<3 in /usr/local/lib/python3.10/dist-packages (from mlflow==2.7.1) (2.2.1)\n",
            "Collecting databricks-cli<1,>=0.8.7 (from mlflow==2.7.1)\n",
            "  Downloading databricks_cli-0.18.0-py2.py3-none-any.whl.metadata (4.0 kB)\n",
            "Requirement already satisfied: entrypoints<1 in /usr/local/lib/python3.10/dist-packages (from mlflow==2.7.1) (0.4)\n",
            "Collecting gitpython<4,>=2.1.0 (from mlflow==2.7.1)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: pyyaml<7,>=5.1 in /usr/local/lib/python3.10/dist-packages (from mlflow==2.7.1) (6.0.2)\n",
            "Requirement already satisfied: protobuf<5,>=3.12.0 in /usr/local/lib/python3.10/dist-packages (from mlflow==2.7.1) (3.20.3)\n",
            "Collecting pytz<2024 (from mlflow==2.7.1)\n",
            "  Downloading pytz-2023.4-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Requirement already satisfied: requests<3,>=2.17.3 in /usr/local/lib/python3.10/dist-packages (from mlflow==2.7.1) (2.32.3)\n",
            "Collecting packaging<24 (from mlflow==2.7.1)\n",
            "  Downloading packaging-23.2-py3-none-any.whl.metadata (3.2 kB)\n",
            "Collecting importlib-metadata!=4.7.0,<7,>=3.7.0 (from mlflow==2.7.1)\n",
            "  Downloading importlib_metadata-6.11.0-py3-none-any.whl.metadata (4.9 kB)\n",
            "Requirement already satisfied: sqlparse<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow==2.7.1) (0.5.1)\n",
            "Collecting alembic!=1.10.0,<2 (from mlflow==2.7.1)\n",
            "  Downloading alembic-1.13.2-py3-none-any.whl.metadata (7.4 kB)\n",
            "Collecting docker<7,>=4.0.0 (from mlflow==2.7.1)\n",
            "  Downloading docker-6.1.3-py3-none-any.whl.metadata (3.5 kB)\n",
            "Requirement already satisfied: Flask<3 in /usr/local/lib/python3.10/dist-packages (from mlflow==2.7.1) (2.2.5)\n",
            "Requirement already satisfied: scipy<2 in /usr/local/lib/python3.10/dist-packages (from mlflow==2.7.1) (1.13.1)\n",
            "Collecting querystring-parser<2 (from mlflow==2.7.1)\n",
            "  Downloading querystring_parser-1.2.4-py2.py3-none-any.whl.metadata (559 bytes)\n",
            "Requirement already satisfied: sqlalchemy<3,>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from mlflow==2.7.1) (2.0.32)\n",
            "Requirement already satisfied: scikit-learn<2 in /usr/local/lib/python3.10/dist-packages (from mlflow==2.7.1) (1.3.2)\n",
            "Collecting pyarrow<14,>=4.0.0 (from mlflow==2.7.1)\n",
            "  Downloading pyarrow-13.0.0-cp310-cp310-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
            "Requirement already satisfied: markdown<4,>=3.3 in /usr/local/lib/python3.10/dist-packages (from mlflow==2.7.1) (3.6)\n",
            "Requirement already satisfied: matplotlib<4 in /usr/local/lib/python3.10/dist-packages (from mlflow==2.7.1) (3.7.1)\n",
            "Collecting gunicorn<22 (from mlflow==2.7.1)\n",
            "  Downloading gunicorn-21.2.0-py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: Jinja2<4,>=2.11 in /usr/local/lib/python3.10/dist-packages (from mlflow==2.7.1) (3.1.4)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly==5.15.0) (9.0.0)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.10/dist-packages (from pandas==1.3.5) (2.8.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers==4.43.3) (3.15.4)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers==4.43.3) (0.23.5)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers==4.43.3) (2024.5.15)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers==4.43.3) (0.4.4)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers==4.43.3) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers==4.43.3) (4.66.5)\n",
            "Collecting Mako (from alembic!=1.10.0,<2->mlflow==2.7.1)\n",
            "  Downloading Mako-1.3.5-py3-none-any.whl.metadata (2.9 kB)\n",
            "Requirement already satisfied: typing-extensions>=4 in /usr/local/lib/python3.10/dist-packages (from alembic!=1.10.0,<2->mlflow==2.7.1) (4.12.2)\n",
            "Requirement already satisfied: pyjwt>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from databricks-cli<1,>=0.8.7->mlflow==2.7.1) (2.9.0)\n",
            "Requirement already satisfied: oauthlib>=3.1.0 in /usr/local/lib/python3.10/dist-packages (from databricks-cli<1,>=0.8.7->mlflow==2.7.1) (3.2.2)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from databricks-cli<1,>=0.8.7->mlflow==2.7.1) (0.9.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.10/dist-packages (from databricks-cli<1,>=0.8.7->mlflow==2.7.1) (1.16.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.7 in /usr/local/lib/python3.10/dist-packages (from databricks-cli<1,>=0.8.7->mlflow==2.7.1) (2.0.7)\n",
            "Requirement already satisfied: websocket-client>=0.32.0 in /usr/local/lib/python3.10/dist-packages (from docker<7,>=4.0.0->mlflow==2.7.1) (1.8.0)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask<3->mlflow==2.7.1) (3.0.3)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask<3->mlflow==2.7.1) (2.2.0)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython<4,>=2.1.0->mlflow==2.7.1)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl.metadata (1.2 kB)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers==4.43.3) (2024.6.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.10/dist-packages (from importlib-metadata!=4.7.0,<7,>=3.7.0->mlflow==2.7.1) (3.19.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2<4,>=2.11->mlflow==2.7.1) (2.1.5)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow==2.7.1) (1.2.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow==2.7.1) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow==2.7.1) (4.53.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow==2.7.1) (1.4.5)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow==2.7.1) (9.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib<4->mlflow==2.7.1) (3.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow==2.7.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow==2.7.1) (3.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.17.3->mlflow==2.7.1) (2024.7.4)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2->mlflow==2.7.1) (1.4.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn<2->mlflow==2.7.1) (3.5.0)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from sqlalchemy<3,>=1.4.0->mlflow==2.7.1) (3.0.3)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython<4,>=2.1.0->mlflow==2.7.1)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl.metadata (4.3 kB)\n",
            "Downloading mlflow-2.7.1-py3-none-any.whl (18.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.5/18.5 MB\u001b[0m \u001b[31m50.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.2/18.2 MB\u001b[0m \u001b[31m46.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pandas-1.3.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.5/11.5 MB\u001b[0m \u001b[31m51.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading transformers-4.43.3-py3-none-any.whl (9.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.4/9.4 MB\u001b[0m \u001b[31m59.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading alembic-1.13.2-py3-none-any.whl (232 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m233.0/233.0 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading databricks_cli-0.18.0-py2.py3-none-any.whl (150 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.3/150.3 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker-6.1.3-py3-none-any.whl (148 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m148.1/148.1 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m14.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gunicorn-21.2.0-py3-none-any.whl (80 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.2/80.2 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading importlib_metadata-6.11.0-py3-none-any.whl (23 kB)\n",
            "Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-13.0.0-cp310-cp310-manylinux_2_28_x86_64.whl (40.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m40.0/40.0 MB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytz-2023.4-py2.py3-none-any.whl (506 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m506.5/506.5 kB\u001b[0m \u001b[31m26.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading querystring_parser-1.2.4-py2.py3-none-any.whl (7.9 kB)\n",
            "Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Mako-1.3.5-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.6/78.6 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Installing collected packages: pytz, smmap, querystring-parser, packaging, numpy, Mako, importlib-metadata, pyarrow, pandas, gunicorn, gitdb, docker, databricks-cli, alembic, gitpython, transformers, mlflow\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2024.1\n",
            "    Uninstalling pytz-2024.1:\n",
            "      Successfully uninstalled pytz-2024.1\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.1\n",
            "    Uninstalling packaging-24.1:\n",
            "      Successfully uninstalled packaging-24.1\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: importlib-metadata\n",
            "    Found existing installation: importlib_metadata 8.2.0\n",
            "    Uninstalling importlib_metadata-8.2.0:\n",
            "      Successfully uninstalled importlib_metadata-8.2.0\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 14.0.2\n",
            "    Uninstalling pyarrow-14.0.2:\n",
            "      Successfully uninstalled pyarrow-14.0.2\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.1.4\n",
            "    Uninstalling pandas-2.1.4:\n",
            "      Successfully uninstalled pandas-2.1.4\n",
            "  Attempting uninstall: transformers\n",
            "    Found existing installation: transformers 4.42.4\n",
            "    Uninstalling transformers-4.42.4:\n",
            "      Successfully uninstalled transformers-4.42.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "xgboost 2.1.1 requires nvidia-nccl-cu12; platform_system == \"Linux\" and platform_machine != \"aarch64\", which is not installed.\n",
            "arviz 0.18.0 requires pandas>=1.5.0, but you have pandas 1.3.5 which is incompatible.\n",
            "bigframes 1.13.0 requires pandas>=1.5.0, but you have pandas 1.3.5 which is incompatible.\n",
            "cudf-cu12 24.4.1 requires pandas<2.2.2dev0,>=2.0, but you have pandas 1.3.5 which is incompatible.\n",
            "cudf-cu12 24.4.1 requires pyarrow<15.0.0a0,>=14.0.1, but you have pyarrow 13.0.0 which is incompatible.\n",
            "geopandas 0.14.4 requires pandas>=1.4.0, but you have pandas 1.3.5 which is incompatible.\n",
            "google-colab 1.0.0 requires pandas==2.1.4, but you have pandas 1.3.5 which is incompatible.\n",
            "plotnine 0.12.4 requires pandas>=1.5.0, but you have pandas 1.3.5 which is incompatible.\n",
            "statsmodels 0.14.2 requires pandas!=2.1.0,>=1.4, but you have pandas 1.3.5 which is incompatible.\n",
            "xarray 2024.6.0 requires pandas>=2.0, but you have pandas 1.3.5 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed Mako-1.3.5 alembic-1.13.2 databricks-cli-0.18.0 docker-6.1.3 gitdb-4.0.11 gitpython-3.1.43 gunicorn-21.2.0 importlib-metadata-6.11.0 mlflow-2.7.1 numpy-1.26.2 packaging-23.2 pandas-1.3.5 pyarrow-13.0.0 pytz-2023.4 querystring-parser-1.2.4 smmap-5.0.1 transformers-4.43.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1fFOUJ_AXKx_"
      },
      "outputs": [],
      "source": [
        "import mlflow\n",
        "\n",
        "# Set the tracking URI for MLflow to the local server\n",
        "mlflow.set_tracking_uri(\"http://localhost:5000\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j1SEl798XKyA"
      },
      "source": [
        "- **What is MLflow?**: MLflow is an open-source platform for managing the end-to-end machine learning lifecycle. It includes tools for tracking experiments, packaging code into reproducible runs, and sharing and deploying models.\n",
        "- **Setting up MLflow**: The first step in using MLflow is to set up the tracking server, where all the experiment data will be stored. ```mlflow.set_tracking_uri(\"http://localhost:5000\")``` sets the tracking URI to a local server (running on localhost at port 5000). This means all the data from your experiments will be sent to this server for tracking and storage.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-anLLIO9XKyA"
      },
      "source": [
        "## **2. Creating and Managing Experiments**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F-Jf9bqJXKyA"
      },
      "outputs": [],
      "source": [
        "# Creating a new experiment\n",
        "experiment_id = mlflow.create_experiment(\"My New Experiment\")\n",
        "\n",
        "# Starting a new run using a context manager\n",
        "with mlflow.start_run(experiment_id=experiment_id):\n",
        "    # Your ML code goes here\n",
        "    pass\n",
        "\n",
        "\n",
        "# Manually creating a custom named run\n",
        "run = mlflow.start_run(experiment_id=experiment_id, run_name=\"First run\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FehEwPoLXKyA"
      },
      "source": [
        "- **Creating Experiments**: `mlflow.create_experiment(\"My New Experiment\")` creates a new experiment in MLflow. An experiment is a way to organize and keep track of your machine learning runs. Each experiment contains multiple runs.\n",
        "- **Starting Runs**: A \"run\" is a single execution of a machine learning code. MLflow allows you to start a run using two methods:\n",
        "    - **Context Manager**: The `with mlflow.start_run()` syntax automatically starts and ends a run. This is useful as it ensures the run is closed properly after the code block is executed.\n",
        "    - **Manual Management**: You can also start and end a run manually using `mlflow.start_run()` and `mlflow.end_run()`. This method gives you more control over when the run starts and ends."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dJN4zDI4XKyA"
      },
      "source": [
        "## **3. Logging Parameters**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bSFLn0KTXKyB"
      },
      "outputs": [],
      "source": [
        "# Logging multiple parameters\n",
        "mlflow.log_param(\"learning_rate\", 0.01)\n",
        "mlflow.log_param(\"batch_size\", 32)\n",
        "num_epochs = 10\n",
        "mlflow.log_param(\"num_epocs\", num_epochs)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2BVGAlpXKyB"
      },
      "source": [
        "\n",
        "- **Purpose of Logging Parameters**: Parameters are the configuration settings used for your machine learning model. Logging them helps you keep track of which settings were used in each run, which is crucial for experiment reproducibility and comparison.\n",
        "- **How it Works**: The `mlflow.log_param` function logs parameters like learning rate, batch size, and number of epochs. These parameters are then visible in the MLflow UI, allowing you to see how different configurations affect model performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WoKMNwT8XKyB"
      },
      "source": [
        "## **4. Logging Metrics**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LIViS1izXKyB"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "# Logging metrics for each epoch\n",
        "for epoch in range(num_epochs):\n",
        "    mlflow.log_metric(\"accuracy\", np.random.random(), step=epoch)\n",
        "    mlflow.log_metric(\"loss\", np.random.random(), step=epoch)\n",
        "\n",
        "# Logging a time-series metric\n",
        "for t in range(100):\n",
        "    metric_value = np.sin(t * np.pi / 50)\n",
        "    mlflow.log_metric(\"time_series_metric\", metric_value, step=t)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FUsUJEa1XKyB"
      },
      "source": [
        "\n",
        "\n",
        "- **Metrics in Machine Learning**: Metrics are values that measure the performance of your model. Common metrics include accuracy and loss.\n",
        "- **Logging Metrics with MLflow**: `mlflow.log_metric` allows you to log these metrics during your training process. This is often done for each epoch (a single pass through the entire dataset), or step (a pass of a batch of data) to track how the model improves over time.\n",
        "- **Time-Series Metrics**: Besides typical metrics, you can also log custom metrics. In this example, a time-series metric based on a sine function is logged. This demonstrates how you can track any metric over time, which can be useful for more complex analyses.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YvOmlQH6XKyB"
      },
      "source": [
        "## **5. Logging Data and Artefacts**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rF6yjSgCXKyB"
      },
      "outputs": [],
      "source": [
        "# Logging datasets\n",
        "with open(\"data/dataset.csv\", \"w\") as f:\n",
        "    f.write(\"x,y\\n\")\n",
        "    for x in range(100):\n",
        "        f.write(f\"{x},{x * 2}\\n\")\n",
        "\n",
        "mlflow.log_artifact(\"data/dataset.csv\", \"data\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j-c8jMBuXKyB"
      },
      "source": [
        "### Exploring different types of artifacts"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rd1xfOkqXKyB"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import plotly.express as px\n",
        "\n",
        "# Generate a confusion matrix\n",
        "confusion_matrix = np.random.randint(0, 100, size=(5, 5))  # 5x5 matrix\n",
        "\n",
        "labels = [\"Class A\", \"Class B\", \"Class C\", \"Class D\", \"Class E\"]\n",
        "df_cm = pd.DataFrame(confusion_matrix, index=labels, columns=labels)\n",
        "\n",
        "# Plot confusion matrix using Plotly Express\n",
        "fig = px.imshow(df_cm, text_auto=True, labels=dict(x=\"Predicted Label\", y=\"True Label\"), x=labels, y=labels, title=\"Confusion Matrix\")\n",
        "\n",
        "# Save the figure as an HTML file\n",
        "html_file = \"confusion_matrix.html\"\n",
        "fig.write_html(html_file)\n",
        "\n",
        "# Log the HTML file with MLflow\n",
        "mlflow.log_artifact(html_file)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i0t8CFgIXKyB"
      },
      "source": [
        "\n",
        "- **What are Artifacts?**: In MLflow, an artifact is any file or data that you want to log along with your run. This can include datasets, models, images, or even custom files.\n",
        "- **Logging Artifacts**: The `mlflow.log_artifact` function allows you to log these artifacts. In this example, a dataset and a confusion matrix (saved as an HTML file) are logged. Logging artifacts helps in ensuring that all relevant data and outputs are stored and easily accessible for each run."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uw-9n7gkXKyC"
      },
      "source": [
        "## **6. Logging Models**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "neWGiUiIXKyC"
      },
      "outputs": [],
      "source": [
        "from transformers import AutoModelForSeq2SeqLM\n",
        "\n",
        "# Initialize a model from Hugging Face Transformers\n",
        "model = AutoModelForSeq2SeqLM.from_pretrained(\"TheFuzzyScientist/T5-base_Amazon-product-reviews\")\n",
        "\n",
        "\n",
        "# Log the model in MLflow\n",
        "mlflow.pytorch.log_model(model, \"transformer_model\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DvPPdEZUXKyC"
      },
      "source": [
        "- **Importance of Logging Models**: Keeping track of the models used in different runs is critical. It helps in model comparison, versioning, and deployment.\n",
        "- **How to Log Models**: MLflow provides functions to log models from various machine learning frameworks. In this case, `mlflow.pytorch.log_model` is used to log a PyTorch model. This function saves the model in a format that can be easily reloaded for future predictions or analysis.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q33syO7vXKyC"
      },
      "source": [
        "## **7. Ending the Run**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZrQOpp86XKyC"
      },
      "outputs": [],
      "source": [
        "# End run\n",
        "mlflow.end_run()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GsMVtB63XKyC"
      },
      "source": [
        "- **What Does Ending a Run Mean?**: In MLflow, ending a run signifies the completion of a specific machine learning experiment or process. It marks the point where you have finished logging parameters, metrics, and artifacts for that particular execution of your model or script.\n",
        "\n",
        "- **Why is it Important?**: It helps in keeping your experiments organized. Each run is a separate record in MLflow. By ending a run, you ensure that all the data logged after this point will be part of a new run, keeping your experiment's data clean and segregated.\n",
        "\n",
        "- **How to End a Run**: You can end a run using `mlflow.end_run()`. This method is particularly important when you start a run without using a context manager (the `with` statement). With a context manager, the run is automatically ended when you exit the block of code inside the `with` statement. However, if you start a run manually using `mlflow.start_run()`, you should always ensure to call `mlflow.end_run()` once all logging is done.\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "dev",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}